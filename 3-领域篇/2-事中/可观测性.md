## 一、可观测性领域概述
可观测性不是一个新名词，来源于控制理论（Control Therory)，指可以由系统外部输出推断其内部状态，广泛应用于电气、机械工程等工业领域。这个概念在2017年被引入微服务和云原生领域，随后在CNCF蓝图里占据了一个重要的组成部分。
### 1. 可观测性的定义
如果你不能测量它，你就无法管理它。 - Peter Drucker
**可观测性的目的是为了更好地管理系统**，帮助我们理解和度量系统运行的状态，判断一是否有可以优化的空间，以及定位如下问题：

- 每个服务的状态如何，是否在按预期处理请求？
- 请求为什么会失败？
- 客户请求都经过了哪些服务，调用链上是否有性能瓶颈？
### 2. 可观测性的支柱
可观测性这个领域，经过若干年的不断发展， 开始逐步在业界形成一定的共识， 具体包括如下几个主要的方面：

- **指标：**一个时间段内累计的度量或计数，它具有原子性，并且是可累加的。比如某次请求使用了多少内存，某个服务在过去的一段时间内处理了多少请求等。
- **日志：**系统事件的记录，这些事件是不连续且不可变的。
- **追踪：**单次请求范围内的信息，某次请求生命周期内所有的数据、元数据信息都被绑定到单个事务上。

**我们用一个分布式的、基于微服的系统，典型排查问题的流程来进行说明：**
> 1. 先通过预设的告警发现异常（通常是指标或日志数据）
> 2. 发现异常后，通过分布式追踪系统记录的调用链信息定到出问题的服务（追踪数据）。
> 3. 查询并分析出问题的服务日志，找到关键的报错信息，从而定位到引发问题的代码、配置等（日志数据）

可以看到这是一个层层深入不断递进的过程。因此可观测性的几个方面都是不可或缺的。

![](static/chap3-6.png)
### 3. 可观测性与监控的区别
简单来说，监控是可观测性的子集和关键功能，两者相辅相成，系统如果达不到某种程度的可观测性就无法监控。

- 监控告诉我们系统整体的运行状态如何，什么时候出了什么问题。
- 可观测性则进一步帮助我们找到出现问题的原因。

![](static/chap3-7.png)

## 二、可观测性平台演进
### 1. 领域平台架构
虽然在业界涌现出了非常多的可观测性领域产品或者技术，但是我们认为这些大都是成单点状的。要做好整体的可观测性的平台，是需要一个整体的规划和理论指导的。经过多年实践经验的总结，大致需要建设如下图展示的整体方案，包含：

1. 业务场景接入
2. 偏重领域特点的产品解决方案
3. 经过抽象的核心产品服务
4. 对长尾部与灵活诉求的二次开发能力
5. 基础的采集/计算/存储能力构建的风险领域数据湖

![](static/chap3-8.png)
### 2. 全息观测能力
所谓的全息观测能力，是能力上支持并融合各项可观测能力（如指标、trace、日志、性能分析）；再者覆盖面上可以做到一站式解决端到端的各类组件。这两点共同解决了数据孤岛问题。以前观测类平台往往是四分五裂的状态，所有平台都尝试从自身的角度出发，去解决业务系统的观测问题。但是这样最终带来的是“断头路”的效果，数据只有真正能相互流通关联的时候，才能真正发挥其作用。包括Google也在其论文中披露，其内部监控平台也是从各个团队自行运维的borgmon逐渐收拢到统一的平台Monarch上，以解决在应急和数据分析过程中跨组件，跨部门的隔阂。
#### 2.1 可观测性几大能力融合
就观测能力而言，每类观测能力均有其优势与不足。比如，指标类数据是可以方便地展现一个实体（或大或小）随时间变化的趋势。而日志能获取明细数据，在排查具体问题的时候非常有用。trace的话往往是站在业务请求的角度，可以串联这一次请求中的上下文。观测平台的演进上，需要逐步建立以指标和日志外加trace的各种能力。并且更为关键的是，平台需要融合了这三方面能力，使之能够各取所长。
#### 2.2 端到端的观测能力
现代互联网企业提供的服务往往不仅涉及到服务端，还涉及到了非常多的客户端技术。而且服务端也不仅只有业务应用程序，还涉及到了非常多的基础设施、中间件、大数据组件、数据库等。一站式覆盖端到端所有各具特点、同时又有一定共性的组件的观测问题，整体解决观测数据碎片化问题是平台演进的一个方向
#### 2.3 软件全生命周期观测
除了常规的观测能力之外，更加注重了在整个软件生命周期中关键节点的观测能力。我们注意到，比如生产环境中的故障，大部分都是在变更的过程中产生的。因此，除了常规的生产环境的持续指标监控观测之外，还需要着力建设灰度、仿真等环境的观测。对于变更这一动态过程，可以针对性的做了变更监控产品。
### 3. 平台核心技术
可观测性平台，作为一个垂直领域，以大量数据驱动的技术领域，也存在着非常多的核心技术点。重点包括做数据采集技术，实时计算技术，时序数据库，日志存储等。
#### 3.1 时序数据库
时序数据库主要使用于应用性能监控（APM）领域，主要是做 grafana 等监控大盘背后的“无名英雄”。时序数据库的核心能力就是海量监控数据的实时写入、高效存储以及实时查询。但是随着时间序列这个概念被人们所熟知，时序数据库的应用场景也逐渐拓展到5G、IoT、车联网等领域，时序数据库中也被用来存储实际工业系统的运行指标、传感器采集的指标数据、车辆行驶数据等等。
随着时序数据中存储的数据越来越多样，查询原始数据并画图已经不再是全部的使用场景，时序数据库必须提供更复杂的查询能力，以便于支持用户从监控数据中快速提取知识，比如查询特定区域某些机器总体健康状况，这就对时序数据分组聚合的能力提出了更高的要求。
多种时序数据库也对查询语言进行了不同方向的探索，有使用 RESTFul API 以便于简化客户端的（OpenTSDB）；有使用类 SQL 语言兼顾用户习惯与时序特色的（InfluxDB）；有使用标准 SQL 的（TimescaleDB）；有使用函数式数据查询脚本的（InfluxDB 2.0）；有自创查询语言的（Kdb+）。当前时序数据库领域是数据库领域的热门细分方向，不过目前还没有一款产品有足够的统治力一统天下。
#### 3.2 日志存储
日志作为可观测性的重要组成部分在开发、运维、测试、审计等过程中起着非常重要的作用。著名的应用开发十二要素中提到：“日志使得应用程序运行的动作变得透明，应用本身从不考虑存储自己的输出流。 不应该试图去写或者管理日志文件。每一个运行的进程都会直接输出到标准输出（stdout）。每个进程的输出流由运行环境截获，并将其他输出流整理在一起，然后一并发送给一个或多个最终的处理程序，用于查看或是长期存档。”
那么在这段描述句中，最重要的就是这个日志存储引擎的实现了。当前云原生时代下日志的处理方案选型也非常多。包括常用的开源方案中的前辈 elasticsearch，后起之秀 Loki。也有一些商用的方案比如阿里云的 SLS，腾讯云的CLS等。
日志场景和其他应用场景相比，最大的区别就是存在热数据和冷数据。热数据是指当天或者近期的索引，这些索引存在增量写入，且查询的QPS相对较高。冷数据是指数天前的索引，已经没有增量写入，且查询QPS不高。那么这些日志引擎核心需要解决的问题就是存储成本，索引效率（查询性能）。
#### 3.3 实时计算技术
当可观测平台处理的业务量比较小的时候，我们认为单纯的查询引擎就能解决问题。比如prometheus 的逻辑都是通过查询来解决后续数据展现和告警的诉求。但是当数据体量太大，查询请求很多的时候，出于性能成本稳定性等各方面诉求，一般我们会引入实时计算技术。另外为什么我们使用的是实时技术也跟可观测性的业务特征有关，具体举个例子比如故障告警场景，时效性是非常关键的。
大家对hadoop 、spark这样的离线框架比较熟悉，与之相对应的是**实时计算**。实时计算它描述快速的计算过程和快速的请求响应。实时计算描述的是计算链路的表达，是实时业务实时计算的需求特征。离线计算强调的是它的离线特征，即非实时的，非实时的计算过程和非实时的请求响应。业务特征是，不求特快，只求结果。
常规的实时计算技术栈会使用 kafka 做数据队列，然后后续由 Flink 或者 spark 这样的实时计算框架进行处理。实时计算框架一般具有以下几个特点：

- **实时性**: 从事件产生到系统的响应之间的延迟在毫秒 或者秒级别;
- **时效性**：实时计算得到的结果、当前状态往往仅仅限于当时几秒钟或者几分钟之内，超过这个时间范围，系统响应将会变得无意义；
- **解耦性**: 产生事件的系统和响应系统之间的是解耦的，一般采用消息队列来解耦，产生事件的系统不能直接调用响应系统;
- **分布式：**采用分布式并行计算的部署方式，以防止瞬间大量事件骤发时产生事件堆积，时效性受到影响；
#### 3.4 采集技术
我们将所有的数据摄取与输入称之为采集。这里针对我们不同数据有非常多可选的采集方式。
对于时序数据的采集，平台需要分成主动采集和被动采集。所谓被动采集相对比较简单，是用户无论通过何种方式，用户通过平台的push gateway不断写入数据，最终通过时序数据平台来存储、二次计算、管理数据，并提供给上层产品进行服务。
主动采集相对比较复杂，但是但是我们通过丰富的插件扩展体系、官方提供的SDK、抽象统一采集配置模型去解决此问题。采集的要素需要抽象一下，主要有这几个点：采集对象（被观测实体）、采集规则、采集频率、采集执行位置（采集任务的路由，典型的比如网络探测是在被观测对象的外部进行采集的、容器的数据是在其所在的物理机上执行的）。这些点需要各个击破。
具体到采集执行层的技术，我认为主要包括：

- 主动埋点SDK（含比如 java 的自动化 instrument 技术）
- 日志采集技术
- 采集数据传输链路
- profiling 技术
## 三、可观测性开源社区产品现状与选型
现阶段的产品基本上各有侧重，大部分侧重于观察性三大支柱中的某一分支，目前仍缺少能够同时处理和关联三大支柱的大统一产口。

- 侧重指标：Prometheus、InfluxDB、Cortex、Zabbix、Nagios等。
- 侧重日志：ELK、Fluentd、Splunk、Loggly等。
- 侧重追踪：Jaeger、Zipkin、SkyWalking、OpenTracing等。

![](static/chap3-9.png)
利用这些开源产品的组合，可以比较快速的搭建一个可观测性系统。但是真正用起来会发现各种各样的问题。总结起来有如下几点：

- 组件繁多: 针对Metrics, Traces, Logs三种数据，往往需要搭建三套独立的系统，内部涉及的组件更多，维护成本很高。
- 数据不互通：同一个应用不同类型的数据被存储在相互独立的系统，数据不互通，难以发挥数据最大的价值。
- 厂商绑定：一些商业产品没有遵守社区标准，在数据采集、传输、存储、可视化、告警等阶段都可能与厂商绑定。后续更换方案的成本巨大。

**OpenTelemetry**
针对以上问题，CNCF社区推出了OpenTelemetry项目。该项目雄心勃勃，旨在统一Metrics、Logs、Traces三种数据，实现可观测性大一统。
